# A chronology of deep learning

Hey everyone who is reading this! 

So what is the hook with deep learning? Why is everyone talking about it? What happened? Well, in the last three decades, a lot of awesome ideas came out, leading to exceptional breakthroughs on general benchmark tasks to evaluate AI systems performance, like image classification, voice recognition, etc. To get the bigger picture, this repo tries to list in chrnological order the main papers about deep learning. 

## 1980s

* Deep learning would exist as it exists now if it was not for Geoffrey Hinton, David Rumelhart and Ronald Williams invention of the Backpropagation algorithm: \
[Learning representations by back-propagating erros](http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf), Hinton et al., 1986, Nature, 14500 citations\
From this point, it was possible to train arbitrarily deep feed-forward neural networks. 

* A few years after, training deep recurrent nets was detailed in this paper: \
[A Learning algorithm for continually running fully recurrent neural networks](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.9724&rep=rep1&type=pdf), Williams et al., 1989, Neural Computation, 2913 citations

## 1990s

## 2000s

## 2010s

### 2010-2011

### 2012

### 2013

### 2014

### 2015

### 2016

### 2017
